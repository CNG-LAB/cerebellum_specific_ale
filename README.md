# Cerebellum-Specific ALE (C-SALE)

This repository contains code and data associated with the paper 'Bias-accounting meta-analyses overcome cerebellar neglect to refine the cerebellar behavioral topography' by Magielse, Manoli, Eickhoff, Fox, Saberi*, and Valk*.


## Graphical Abstract
![alt text](./output/figures/graphical_abstract.png)

## Short Description
In this study we adapted the [Activation Likelihood Estimation method for coordinate-based meta-analysis](https://doi.org/10.1016/j.neuroimage.2011.09.017) to account for unequal distributions of reported effects. We describe how in the entire brain, but especially the cerebellum, foci distributions are highly skewed. The overrepresentation of superior cerebellar foci - likely related to historical neglect of the cerebellum in neuroimaging studies - results in inaccurate locations of cerebellar convergence across task domains. Our new method, Cerebellum-Specific ALE (C-SALE) much improves specificity of convergence in the cerebellum. We extensively characterize these maps, through repeated subsampling and correspondence to existing cerebellar parcellations. We then use this new debiased framework to perform whole-brain meta-analytic connectivty modelling (MACM), showing brain-wide cerebellar coactivation networks and illustrating how the new method can be translated to any volumetric brain region-of-interest. Besides providing our full code (except the raw BrainMap data, see **Additional Requirements**) we provide a graphical-processing unit implementation of ALE that can greatly speed-up analyses at: [amnsbr/nimare-gpu](https://github.com/amnsbr/nimare-gpu).

## Repository Structure
- `scripts/`: Includes the scripts used to run the analyses and produce full output of this study.
    - `Figures/`: Contains Jupyter Notebooks used to generate the figures for the paper. Figures are numbered as in the preprint.
    - `run_meta.py`: Runs the ALE or C-SALE meta-analyses. Usage: `python run_meta.py --help`.
      We ran the meta-analyses using HTCondor on our (INM-7 Forschungszentrum JÃ¼lich) cluster by first creating DAGman files using `gen_dag_meta.py` which
      submit jobs based on `run_meta.submit`.
    - `run_macm.py`: Runs the MACM analysis with significant clusters of input thresholded map. Usage: `python run_macm.py --help`.
      We ran the MACM meta-analyses using HTCondor on our cluster by first creating DAGman files using `gen_dag_macm.py` which
      submit jobs based on `run_macm.submit`.
    - `run_variogram.py`: Calculates variogram-based SA-preserving surrogates of the input unthresholded map. Usage: `python run_variogram.py --help`.
      We create the variogram surrogates using HTCondor on our cluster by first creating DAGman files using `gen_dag_variogram.py` which
      submit jobs based on `run_variogram.submit`.
    - `run_scaling.py`: Runs scaling analyses of compute time on CPU and GPU. Usage: `python run_scaling.py <analysis> <n_iters> <n_exp> <use_gpu>`.
      We ran these using HTCondor on our cluster by first creating DAGman files using `gen_dag_scaling.py` which
      submit jobs based on `run_scaling_cpu.submit` or `run_scaling_gpu.submit`.
    - `utils.py`: Utility functions used to run the analyses and create the figures
- `tools/`: Includes SUITPy. This toolkit is a dependency of most scripts.
- `input/`: Necessary input to perform our study. Note that this excludes raw BrainMap data.
- `output/`: Full output created in this study.
    - `data/`: Data derived from BrainMap used in the meta-analyses.
    - `SALE/`: Results of the C-SALE meta-analyses.
    - `ALE/`: Results of the ALE meta-analyses.
    - `exp_stats.csv`: Experiment statistics for each behavioral domain in C-SALE analyses.
    - `macm_exp_stats.csv`: Experiment statistics for each behavioral domain in the MACM analyses.
    - `figures/`: Includes figures generated by the scripts in `scripts/Figures/`.

## Additional Requirements
In addition to the Python dependencies specified in `requirements.txt` and the `tools` directory, the following are required for the scripts to run:
- The BrainMap dataset is expected to be located at `output/data/BrainMap_dump_Feb2024.pkl.gz`. Due to access restrictions, this file and its derivative datasets used in the meta-analyses are not shared in the repository but can be provided upon request and after completion of a data usage agreement. Note that the BrainMap database is also searchable using [Sleuth](https://www.brainmap.org/sleuth/).
- The environment variables `$PROJECT_DIR` must be defined and point to the project's root directory.

## Support
If you have any questions, feel free to contact Neville Magielse (neville.magielse\[at\]gmail.com) or Amin Saberi (amnsbr\[at\]gmail.com).
